# Ecossistema de Ferramentas e Frameworks

O crescimento da Intelig√™ncia Artificial trouxe consigo um **ecossistema diverso de ferramentas e frameworks**, que aceleram a cria√ß√£o, teste e implanta√ß√£o de solu√ß√µes. Esses recursos permitem que equipes foquem no **valor de neg√≥cio** em vez de reinventar a roda do zero.  

Neste cap√≠tulo, vamos explorar algumas das ferramentas mais utilizadas atualmente, com foco em suas aplica√ß√µes pr√°ticas, pontos fortes e limita√ß√µes.  

---

## LangFlow

O **LangFlow** √© uma interface visual que facilita a constru√ß√£o de aplica√ß√µes com modelos de linguagem. √â uma ferramenta de c√≥digo aberto, desenvolvida em Python, que funciona como um **‚Äúlaborat√≥rio de fluxos‚Äù**, no qual prompts, APIs, bancos de dados e l√≥gica de neg√≥cio podem ser conectados de forma intuitiva, sem necessidade de programa√ß√£o aprofundada. Por reduzir barreiras t√©cnicas, √© especialmente √∫til para **equipes multidisciplinares** (como marketing e inova√ß√£o) que querem experimentar IA de forma √°gil {cite}`langflow2023`. √â ideal para prototipagem r√°pida de aplica√ß√µes de IA e experimenta√ß√£o com diferentes modelos e arquiteturas de fluxo.

```{admonition} Principais usos
:class: note  
- Cria√ß√£o de prot√≥tipos de chatbots em minutos.  
- Testes r√°pidos de **Prompt Engineering** com diferentes entradas.  
- Constru√ß√£o de **Proofs of Concept (PoCs)** para valida√ß√£o junto a stakeholders.
```

```{admonition} Principais caracter√≠sticas
:class: note

- Interface visual drag-and-drop para constru√ß√£o de fluxos de IA
- Compatibilidade com diversos modelos de linguagem e embeddings
- Suporte a m√∫ltiplos provedores de IA (OpenAI, Anthropic, etc)
- Exporta√ß√£o de fluxos como c√≥digo Python
```

Integra√ß√£o com MCP: √© poss√≠vel trabalhar com o LangFlow integrando-o ao MCP (Model Context Protocol), veja [Se√ß√£o Model Context Protocol](secao_mcp), permitindo que o fluxo interaja com m√∫ltiplos modelos e ferramentas de forma padronizada, escal√°vel e interoper√°vel.

Para trabalhar com o MCP:

- Configure diferentes modelos de linguagem como n√≥s
- Estabele√ßa regras de roteamento entre modelos
- Defina estrat√©gias de fallback autom√°tico
- Monitore uso e custos por provedor


O LangFlow pode ser enquadrado n√£o apenas como uma ferramenta, mas como um paradigma de desenvolvimento distinto. 

```{admonition} Proposta de valor central do LangFlow
:class: note
Acelerar o desenvolvimento de aplica√ß√µes de Intelig√™ncia Artificial (IA) atrav√©s de uma interface visual de baixo c√≥digo (low-code), constru√≠da sobre as funda√ß√µes do ecossistema LangChain.
```

### Definindo o LangFlow: Al√©m de uma UI para o LangChain

O LangFlow √© uma plataforma visual de c√≥digo aberto que simplifica a cria√ß√£o de aplica√ß√µes com Gera√ß√£o Aumentada por Recupera√ß√£o (RAG) e estruturas baseadas em m√∫ltiplos agentes. Seu grande diferencial est√° na interface intuitiva de arrastar e soltar, que substitui a escrita de c√≥digo tradicional por uma experi√™ncia acess√≠vel e visual. Assim, mesmo quem n√£o domina programa√ß√£o pode construir fluxos de trabalho inteligentes com facilidade.

Embora tenha surgido como uma simples interface gr√°fica para o LangChain, o LangFlow evoluiu rapidamente. Hoje, ele se consolidou como uma ferramenta poderosa para prototipagem e experimenta√ß√£o √°gil de sistemas de IA. Gra√ßas √† sua abordagem visual, a plataforma derruba barreiras t√©cnicas e convida at√© mesmo usu√°rios iniciantes ‚Äî ou de √°reas n√£o t√©cnicas ‚Äî a explorarem o desenvolvimento de solu√ß√µes complexas com IA.

Outro ponto forte do LangFlow √© sua flexibilidade tecnol√≥gica. Ele √© totalmente agn√≥stico em rela√ß√£o a LLMs e bancos de vetores, o que significa que oferece suporte aos principais provedores do mercado. Al√©m disso, conta com uma biblioteca crescente de componentes e integra√ß√µes. Isso garante ao desenvolvedor a liberdade de escolher os melhores recursos para cada projeto, sem se prender a uma tecnologia ou fornecedor espec√≠fico.

---

### O Problema Central Resolvido: Acelerando o Ciclo de Vida do Desenvolvimento de IA

O LangFlow aborda diretamente a natureza lenta e intensiva em c√≥digo da prototipagem de aplica√ß√µes de LLM. A plataforma permite que os desenvolvedores "parem de lutar com as suas ferramentas" e se concentrem em criar "magia de IA". 

Ao visualizar os workflows, facilita a colabora√ß√£o e torna ideias de produtos complexas compreens√≠veis tanto para os stakeholders t√©cnicos como para os n√£o t√©cnicos. Esta clareza visual √© um diferenciador chave, permitindo que as equipas construam e demonstrem workflows de LLM rapidamente.

COLOCAR O GIFF DO LANGFLOW FUNCIONANDO AQUI

A plataforma democratiza o acesso a conceitos poderosos de IA, como agentes, RAG e orquestra√ß√£o de m√∫ltiplas ferramentas, tornando-os tang√≠veis e manipul√°veis sem a necessidade de um conhecimento profundo em programa√ß√£o. Essencialmente, o LangFlow acelera o ciclo de vida do desenvolvimento de IA ao permitir que as equipas transformem rapidamente ideias em prot√≥tipos funcionais, testem diferentes configura√ß√µes e iterem sobre a l√≥gica da aplica√ß√£o com um esfor√ßo m√≠nimo.

A natureza visual do LangFlow traz benef√≠cios que v√£o al√©m da acelera√ß√£o do desenvolvimento individual. Ela transforma a **din√¢mica colaborativa em equipes multidisciplinares** e reduz falhas de comunica√ß√£o entre √°reas t√©cnicas e de neg√≥cio.

**Impacto na Colabora√ß√£o em Equipes H√≠bridas**: O desenvolvimento de solu√ß√µes com IA exige cada vez mais uma atua√ß√£o integrada entre diversos perfis profissionais:

- Engenheiros de software
- Cientistas de dados
- Gestores de produto
- Especialistas de dom√≠nio

:::{admonition}  Problema das Abordagens Tradicionais
:class: warning

Uma abordagem baseada apenas em c√≥digo pode gerar **silos de conhecimento**, onde:
- As necessidades de neg√≥cio s√£o mal interpretadas.
- A tradu√ß√£o para requisitos t√©cnicos gera ru√≠do.
- O processo √© lento e propenso a erros de comunica√ß√£o.
:::

A interface visual de **baixo c√≥digo** do LangFlow funciona como uma **tela compartilhada**, permitindo que diferentes perfis colaborem em tempo real:

```{admonition} LangFlow como "Linguagem Comum"
:class: note

- O **gestor de produto** pode desenhar visualmente a l√≥gica de um agente.
- O **cientista de dados** configura os modelos, par√¢metros e prompts.
- O **engenheiro de software** otimiza, estende ou coloca esse fluxo em produ√ß√£o.
```

Essa colabora√ß√£o **reduz retrabalho**, **acelera itera√ß√µes** e **garante alinhamento entre √°reas**.

**Novas Fun√ß√µes no Desenvolvimento com IA**: A ado√ß√£o de ferramentas como o LangFlow aponta para uma nova configura√ß√£o organizacional:

- Surgem novas fun√ß√µes como:
  :::{grid} 2
:gutter: 2

:::{grid-item}
### üß© Orquestrador de IA

Respons√°vel por planejar, conectar e estruturar os diferentes blocos de uma aplica√ß√£o de IA. Atua como um estrategista t√©cnico, integrando modelos, dados e fluxos para entregar valor ao neg√≥cio.
:::

:::{grid-item}
### üé® Designer de Fluxos

Foca na experi√™ncia visual e funcional dos fluxos de IA. Usa ferramentas no-code ou low-code (como LangFlow) para construir e testar solu√ß√µes, mesmo sem conhecimento avan√ßado em programa√ß√£o.
:::

:::

Esses pap√©is atuam como **pontes entre os requisitos de neg√≥cio e a implementa√ß√£o t√©cnica**, consolidando uma pr√°tica de desenvolvimento mais √°gil, colaborativa e sustent√°vel.

### An√°lise Arquitetural Aprofundada: De Grafos Visuais a Fluxos Execut√°veis

Esta sec√ß√£o desconstr√≥i a arquitetura subjacente do LangFlow, explicando como os designs visuais s√£o traduzidos em l√≥gica execut√°vel e como a plataforma se integra no ecossistema de IA mais amplo.

### O Modelo de Execu√ß√£o: Grafos Ac√≠clicos Direcionados (DAGs)

O n√∫cleo do modelo de execu√ß√£o do LangFlow √© o Grafo Ac√≠clico Direcionado (DAG). Cada "fluxo" (flow) criado na tela √© uma representa√ß√£o visual de um DAG. Quando um fluxo √© executado, o LangFlow constr√≥i um objeto de grafo a partir dos n√≥s (componentes) e das arestas (conex√µes). Os n√≥s s√£o ent√£o ordenados topologicamente para determinar uma ordem de execu√ß√£o estrita e sequencial, baseada nas depend√™ncias entre eles.

Durante a constru√ß√£o do grafo, a fun√ß√£o `def_build` de cada componente √© chamada para validar e preparar o n√≥. O grafo √© ent√£o processado na ordem de depend√™ncia, com a sa√≠da de um n√≥ a ser passada como entrada para o n√≥ seguinte. Este modelo sequencial e ac√≠clico √© altamente eficaz para workflows lineares ou com ramifica√ß√µes, como pipelines de RAG padr√£o, onde o processo √© previs√≠vel: Carregar Dados -> Dividir -> Embutir -> Armazenar -> Recuperar -> Gerar.

No entanto, a natureza "Ac√≠clica" do modelo DAG significa que ele, por defini√ß√£o, n√£o pode suportar ciclos ou la√ßos na sua estrutura de grafo. Esta caracter√≠stica imp√µe uma limita√ß√£o significativa para sistemas de agentes avan√ßados que requerem racioc√≠nio iterativo, la√ßos de autocorre√ß√£o ou comportamentos c√≠clicos e com estado. Esta escolha arquitetural contrasta com frameworks como o LangGraph, que s√£o explicitamente projetadas para lidar com ciclos, oferecendo um paradigma de orquestra√ß√£o mais flex√≠vel para agentes complexos.

---

### Constru√ß√µes Arquiteturais Centrais

A arquitetura do LangFlow √© constru√≠da em torno de tr√™s conceitos fundamentais que trabalham em conjunto para permitir a cria√ß√£o de aplica√ß√µes de IA.

### Fluxos (Flows)

Os fluxos s√£o o artefacto principal no LangFlow. Um fluxo √© um workflow completo e execut√°vel que representa a l√≥gica de uma aplica√ß√£o. Pode ser criado do zero, a partir de modelos pr√©-constru√≠dos, ou importando um ficheiro JSON que define a sua estrutura. Os fluxos encapsulam toda a sequ√™ncia de opera√ß√µes, desde a entrada do utilizador at√© √† sa√≠da final, representando visualmente o percurso dos dados atrav√©s dos v√°rios componentes.

### Componentes

Os componentes s√£o os n√≥s individuais dentro de um fluxo. Cada componente √© uma unidade modular e execut√°vel que realiza uma tarefa espec√≠fica, como interagir com um LLM, carregar dados de uma fonte, ou conectar-se a uma base de dados vetorial. O LangFlow fornece uma vasta biblioteca de componentes, categorizados em grupos como LLMs, Prompts, Carregadores de Dados, Armaz√©ns de Vetores e Ferramentas. Uma caracter√≠stica importante √© a transpar√™ncia: os utilizadores podem inspecionar o c√≥digo Python subjacente a cada componente, permitindo uma compreens√£o mais profunda do seu funcionamento.

### Agentes

Um agente √© um tipo especializado de componente que atua como o "c√©rebro" de um fluxo. Utiliza um LLM para raciocinar, tomar decis√µes e escolher quais "ferramentas" (outros componentes conectados) usar com base na entrada do utilizador. O componente do agente encapsula l√≥gicas complexas, como o padr√£o ReAct (Reason+Act), abstraindo-as do utilizador e simplificando a constru√ß√£o de sistemas que podem interagir dinamicamente com o seu ambiente.

### Interoperabilidade e o Protocolo de Contexto de Modelo (MCP)

O LangFlow evoluiu para ser tanto um servidor como um cliente do Protocolo de Contexto de Modelo (MCP), uma caracter√≠stica cr√≠tica para sistemas de IA modernos e distribu√≠dos. O MCP √© um padr√£o emergente para a comunica√ß√£o entre agentes, permitindo que sistemas de IA descubram e utilizem as capacidades uns dos outros de forma padronizada.

Como um **servidor MCP**, qualquer projeto LangFlow pode expor os seus fluxos constituintes como ferramentas atrav√©s de um endpoint MCP padr√£o. Isto permite que outras aplica√ß√µes compat√≠veis com MCP (por exemplo, um agente constru√≠do com c√≥digo) descubram e orquestrem um workflow constru√≠do visualmente no LangFlow como uma √∫nica e poderosa ferramenta. Por outro lado, como um **cliente MCP**, o LangFlow inclui um componente de Ferramentas MCP que pode conectar-se a servidores MCP externos. Isto permite que um fluxo importe e utilize ferramentas expostas por outras aplica√ß√µes, criando uma rede de agentes interoper√°veis. As atualiza√ß√µes recentes (vers√£o 1.6) adicionaram camadas de seguran√ßa como a autentica√ß√£o OAuth para servidores MCP, sinalizando um movimento em dire√ß√£o a uma comunica√ß√£o segura entre agentes, pronta para produ√ß√£o.

A limita√ß√£o do DAG no LangFlow n√£o √© um descuido, mas sim uma escolha de design deliberada que favorece a simplicidade e a estabilidade em detrimento da flexibilidade total. Os DAGs garantem que os fluxos terminem, evitam la√ßos infinitos e tornam a execu√ß√£o mais previs√≠vel e f√°cil de depurar. Esta abordagem est√° perfeitamente alinhada com o principal caso de uso do LangFlow: a prototipagem r√°pida e fi√°vel de workflows lineares. No entanto, a equipa de desenvolvimento reconheceu claramente a limita√ß√£o que isto imp√µe para a constru√ß√£o de agentes mais sofisticados. A introdu√ß√£o do suporte a MCP n√£o √© apenas uma funcionalidade de interoperabilidade; √© a "sa√≠da de emerg√™ncia" estrat√©gica das restri√ß√µes do DAG. Um desenvolvedor pode construir um agente complexo e c√≠clico usando uma framework baseada em c√≥digo como o LangGraph e expor as suas capacidades atrav√©s de um servidor MCP. Simultaneamente, pode usar a interface visual do LangFlow para construir a parte da aplica√ß√£o virada para o utilizador ou outros subprocessos lineares. A aplica√ß√£o LangFlow pode ent√£o chamar o agente c√≠clico externo como uma "ferramenta" atrav√©s do componente cliente MCP. Esta arquitetura permite que o LangFlow permane√ßa simples e est√°vel internamente (ao impor o modelo DAG), enquanto ainda √© capaz de orquestrar e participar em sistemas multi-agente muito mais complexos e c√≠clicos. O MCP transforma o LangFlow de um construtor aut√≥nomo num componente modular dentro de um ecossistema de IA maior e mais capaz.

---

### **Conclus√£o: A Ponte Visual para a Orquestra√ß√£o de IA**

Nesta sec√ß√£o, estabelecemos o LangFlow como uma poderosa ferramenta de prototipagem visual, cuja arquitetura baseada em Grafos Ac√≠clicos Dirigidos (DAGs) se destaca na acelera√ß√£o do desenvolvimento de workflows lineares, como os pipelines de RAG. A sua interface intuitiva democratiza o acesso √† constru√ß√£o de aplica√ß√µes de IA e serve como uma "linguagem comum" para equipas multidisciplinares.

No entanto, tamb√©m identific√°mos a sua limita√ß√£o arquitetural inerente: a barreira da aciclicidade, que impede a cria√ß√£o de agentes com comportamentos iterativos e de autocorre√ß√£o. A resposta estrat√©gica do LangFlow a esta limita√ß√£o n√£o foi alterar o seu n√∫cleo, mas sim abra√ßar a interoperabilidade atrav√©s do Protocolo de Contexto de Modelo (MCP). O MCP funciona como uma ponte, permitindo que os fluxos lineares e f√°ceis de construir no LangFlow se conectem e orquestrem sistemas externos mais complexos e potencialmente c√≠clicos.

Com esta ponte estabelecida, o pr√≥ximo passo l√≥gico √© explorar a arquitetura dos sistemas que vivem do outro lado ‚Äî aqueles projetados desde o in√≠cio para gerir ciclos, estado e a l√≥gica complexa que define os agentes verdadeiramente aut√≥nomos.

### Hist√≥ria por tr√°s do LangFlow

A plataforma foi desenvolvida pela empresa Logspace, fundada em 2022 pelos mineiros  Rodrigo Nader e Gabriel Almeida. Em entrevistas e publica√ß√µes, o projeto √© frequentemente descrito como uma "ferramenta brasileira".

Rodrigo Nader, um dos fundadores, expressou o objetivo de fortalecer o cen√°rio de tecnologia no pa√≠s, afirmando: 

> "Nosso objetivo √© transformar o Brasil em um polo de inova√ß√£o em intelig√™ncia artificial".

Posteriormente, a empresa foi adquirida pela DataStax, que agora faz parte da IBM.
---

## LangChain

O **LangChain** √© uma das bibliotecas mais populares para desenvolvimento de aplica√ß√µes baseadas em LLMs.  
Ele oferece **componentes reutiliz√°veis e modulares** para:  

- Conectar modelos de linguagem a diferentes fontes de dados.  
- Gerenciar mem√≥ria de conversas de longo prazo.  
- Criar cadeias de racioc√≠nio complexas e pipelines de decis√£o.  

**Exemplo pr√°tico:** criar um assistente corporativo que acessa pol√≠ticas internas em PDF, responde d√∫vidas e registra feedback dos colaboradores.  

Seu diferencial est√° na **flexibilidade para integrar IA em aplica√ß√µes robustas**, tornando-o uma escolha comum para startups e grandes empresas {cite}`langchain2022`.  

----TEXTO----NOTION----
LangChain √© um framework de c√≥digo aberto que facilita o desenvolvimento de aplica√ß√µes com Intelig√™ncia Artificial, especialmente para criar agentes de IA. Suas principais caracter√≠sticas incluem:

- **Componentes Modulares:** Oferece blocos de constru√ß√£o reutiliz√°veis para criar aplica√ß√µes de IA personalizadas
- **Integra√ß√£o com LLMs:** Suporta diversos modelos de linguagem como GPT-4, Claude, PaLM e outros
- **Gerenciamento de Contexto:** Permite manipular e estruturar o contexto das conversas de forma eficiente
- **Chains:** Possibilita a cria√ß√£o de fluxos sequenciais de processamento de dados e l√≥gica
- **Agents:** Facilita a constru√ß√£o de agentes aut√¥nomos que podem tomar decis√µes e executar tarefas

**Principais funcionalidades para Backend:**

- **Memory Systems:** Gerenciamento de hist√≥rico de conversas e estados
- **Prompt Templates:** Sistema robusto para gerenciar e padronizar prompts
- **Tools e Callbacks:** Integra√ß√£o com APIs externas e sistemas de monitoramento
- **Document Loaders:** Processamento de diferentes tipos de documentos e dados

**Vantagens para Desenvolvimento:**

- Arquitetura modular e extens√≠vel
- Grande comunidade e documenta√ß√£o abrangente
- Suporte a diversos backends de banco de dados
- Integra√ß√£o facilitada com servi√ßos de nuvem

```{code-block} python
from langchain.agents import Tool, AgentExecutor, LLMSingleActionAgent
from langchain.memory import ConversationBufferMemory

# Exemplo b√°sico de configura√ß√£o de um agente
tools = [
    Tool(
        name="Search",
        func=search_function,
        description="√ötil para buscar informa√ß√µes"
    )
]

memory = ConversationBufferMemory()
agent = LLMSingleActionAgent(tools=tools, memory=memory)
agent_executor = AgentExecutor.from_agent_and_tools(
    agent=agent,
    tools=tools,
    memory=memory
)
```

-----parte mateus
**Introdu√ß√£o ao LangChain e frameworks similares**

Para superar essas limita√ß√µes, surgiram frameworks como o **LangChain**, **LlamaIndex**, **CrewAI**, **Autogen**, entre outros. O LangChain, por exemplo, permite estruturar aplica√ß√µes que usam LLMs com recursos como:

- **Prompt templates**: Cria√ß√£o de prompts modulares e reutiliz√°veis.
- **Mem√≥ria de conversa**: Persist√™ncia de contexto entre chamadas.
- **Integra√ß√£o com ferramentas**: Permite ao LLM chamar APIs externas, bancos de dados ou executar fun√ß√µes.
- **Agentes**: Um n√≠vel acima, em que o modelo decide o que fazer, quais ferramentas usar e em que ordem.

Essas solu√ß√µes transformam um simples modelo de linguagem em uma **aplica√ß√£o inteligente completa**, com racioc√≠nio aut√¥nomo, tomada de decis√£o e execu√ß√£o de tarefas pr√°ticas.

### **Introdu√ß√£o**

O advento de Modelos de Linguagem de Grande Escala (LLMs) catalisou uma mudan√ßa de paradigma no desenvolvimento de software. As aplica√ß√µes est√£o a evoluir de sistemas transacionais, que respondem a comandos diretos, para "aplica√ß√µes cognitivas" que compreendem, raciocinam e agem com um grau de autonomia sem precedentes. Esta transi√ß√£o introduz uma nova camada de complexidade: a necessidade de orquestra√ß√£o sofisticada. J√° n√£o √© suficiente fazer uma simples chamada de API a um LLM; as aplica√ß√µes modernas devem encadear m√∫ltiplas chamadas, interagir com fontes de dados externas, utilizar ferramentas personalizadas e manter o contexto ao longo de intera√ß√µes complexas. Antes do surgimento de frameworks dedicados, os programadores enfrentavam o desafio de gerir manualmente este fluxo, escrevendo c√≥digo "cola" fr√°gil, dif√≠cil de manter e propenso a erros.

Neste contexto, o LangChain emergiu n√£o apenas como uma ferramenta, mas como um ecossistema de orquestra√ß√£o fundamental, projetado para simplificar a constru√ß√£o de fluxos de trabalho complexos e de m√∫ltiplos passos. Este relat√≥rio serve como um guia t√©cnico definitivo para arquitetos e programadores que procuram navegar neste novo cen√°rio. O seu objetivo √© fornecer uma an√°lise exaustiva que vai desde a integra√ß√£o de c√≥digo personalizado no framework LangChain at√© √† implementa√ß√£o de sistemas de produ√ß√£o escal√°veis e robustos.

Ao longo do texto ser√° tratado:

- Os mecanismos precisos para conectar a l√≥gica de neg√≥cio de um programador ao ecossistema LangChain.
- Uma an√°lise comparativa aprofundada das filosofias de orquestra√ß√£o do LangChain e do seu sucessor mais avan√ßado, o LangGraph.
- Uma avalia√ß√£o criticamente v√°rios padr√µes de arquitetura de backend, Monol√≠tico, Microsservi√ßos, Serverless e Orientado a Eventos, especificamente adaptados aos desafios √∫nicos das cargas de trabalho de IA.

O objetivo √© capacitar os profissionais t√©cnicos com o conhecimento necess√°rio para transformar uma pe√ßa isolada de c√≥digo de IA num sistema cognitivo totalmente implementado, escal√°vel e resiliente.

---

### **Desmistificando o LangChain: A Ponte Entre o C√≥digo Personalizado e os LLMs**

Esta se√ß√£o aborda a quest√£o fundamental de como um programador pode integrar a sua l√≥gica de IA personalizada no ecossistema LangChain. Para isso, √© essencial primeiro desconstruir o framework, compreendendo a sua filosofia de orquestra√ß√£o e os seus componentes fundamentais, antes de detalhar os pontos de integra√ß√£o precisos atrav√©s do conceito de Ferramentas (Tools).

---

### **A Filosofia de Orquestra√ß√£o do LangChain: De Framework a Ecossistema**

O LangChain √© mais do que uma simples biblioteca; √© um ecossistema abrangente projetado para gerir todo o ciclo de vida de uma aplica√ß√£o alimentada por LLM, desde o desenvolvimento e produ√ß√£o at√© √† implementa√ß√£o. A sua principal proposta de valor reside na abstra√ß√£o da complexidade inerente √† intera√ß√£o com LLMs, fontes de dados e servi√ßos externos, fornecendo uma interface padronizada e modular. Esta abordagem permite que os programadores construam rapidamente prot√≥tipos e iterem em aplica√ß√µes complexas, como chatbots inteligentes, sistemas de perguntas e respostas sofisticados e ferramentas de an√°lise de dados automatizadas.

A evolu√ß√£o da arquitetura do LangChain √© um testemunho da sua maturidade e resposta √†s necessidades da comunidade de programadores. O que come√ßou como um framework mais monol√≠tico transformou-se num ecossistema modular e extens√≠vel. Esta mudan√ßa n√£o √© meramente organizacional; representa uma altera√ß√£o estrat√©gica fundamental. A estrutura atual est√° deliberadamente desagregada em pacotes distintos, cada um com um prop√≥sito claro:

- **`langchain-core`**: O cora√ß√£o do ecossistema. Cont√©m as abstra√ß√µes de base para todos os componentes (como modelos de chat, vector stores, ferramentas) e a LangChain Expression Language (LCEL), que permite compor estes componentes de forma declarativa. As suas depend√™ncias s√£o mantidas propositadamente leves para garantir a estabilidade.
- **`langchain`**: Este pacote cont√©m a "arquitetura cognitiva" da aplica√ß√£o. Inclui implementa√ß√µes gen√©ricas de Chains, Agents e estrat√©gias de recupera√ß√£o de dados.
- **Pacotes de Integra√ß√£o (ex: `langchain-openai`)**: As integra√ß√µes mais populares foram separadas em pacotes leves, permitindo uma gest√£o de vers√µes mais rigorosa e garantindo qualidade atrav√©s da co-manuten√ß√£o pela equipa do LangChain e pelos parceiros.
- **`langchain-community`**: Um reposit√≥rio para uma vasta gama de integra√ß√µes de terceiros mantidas pela comunidade, garantindo que o ecossistema permane√ßa aberto e em constante crescimento.

Esta modularidade aborda diretamente o "inferno de depend√™ncias" (*dependency hell*) e a percep√ß√£o de que o framework era excessivamente "inchado". Ao incentivar novas integra√ß√µes a serem publicadas como pacotes `langchain-*` separados, o ecossistema promove uma melhor gest√£o de depend√™ncias e versionamento. Esta evolu√ß√£o posiciona o `langchain-core` como um sistema nervoso central est√°vel, sobre o qual um universo de ferramentas e integra√ß√µes especializadas pode ser constru√≠do, permitindo que os programadores instalem apenas o que necessitam para criar aplica√ß√µes mais leves e eficientes.

---

### **O Kit de Ferramentas do Programador: Componentes Fundamentais do LangChain**

Para construir uma aplica√ß√£o com o LangChain, um programador utiliza um conjunto de blocos de constru√ß√£o modulares. A compreens√£o de cada um destes componentes e da forma como interagem √© crucial.

- **Modelos (LLMs, Chat Models, Embedding Models)**: Fornecem a interface para o "c√©rebro" da aplica√ß√£o. O LangChain abstrai as APIs de diferentes fornecedores (OpenAI, Anthropic, Google), permitindo intera√ß√µes padronizadas. Os *Embedding Models* s√£o cruciais para converter texto em vetores num√©ricos, a base da busca por similaridade sem√¢ntica.
- **Conex√£o de Dados (Document Loaders, Text Splitters)**: Permitem que a aplica√ß√£o raciocine sobre dados privados ou externos. Os *Document Loaders* ingerem dados de diversas fontes (PDFs, bases de dados, APIs). Como os LLMs t√™m uma janela de contexto finita, os *Text Splitters* dividem documentos grandes em peda√ßos menores e semanticamente coesos.
- **Armazenamento de Dados (Vector Stores)**: Ap√≥s a convers√£o do texto em *embeddings*, estes vetores s√£o armazenados em *Vector Stores* (bases de dados vetoriais). Estas bases de dados s√£o especializadas em indexar e pesquisar vetores de alta dimens√£o, permitindo consultas de baixa lat√™ncia. O LangChain integra-se com mais de 50 op√ß√µes.
- **Recupera√ß√£o (Retrievers)**: Um *Retriever* √© a interface que busca os documentos relevantes do *Vector Store* em resposta a uma consulta. Este componente, juntamente com os anteriores, forma a espinha dorsal da arquitetura de **Gera√ß√£o Aumentada por Recupera√ß√£o (RAG)**, que fundamenta as respostas do LLM em informa√ß√µes externas e factuais.
- **Chains e Agents**: Orquestram os componentes anteriores.
    - **Chains**: Representam uma sequ√™ncia de chamadas. A forma moderna de as construir √© atrav√©s da **LangChain Expression Language (LCEL)**, que utiliza o operador pipe (`|`) para compor componentes de forma declarativa e transparente.
    - **Agents**: Utilizam um LLM para tomar decis√µes. Um agente tem acesso a um conjunto de ferramentas e decide, com base na entrada do utilizador, qual ferramenta usar, como us√°-la e como proceder com a sa√≠da, permitindo um comportamento din√¢mico e aut√≥nomo.

---

### **O Ponto de Conex√£o: Integrando C√≥digo Personalizado via Ferramentas (Tools)**

A verdadeira pot√™ncia do LangChain para um programador reside na sua capacidade de estender as capacidades de um LLM para al√©m da gera√ß√£o de texto, permitindo-lhe interagir com o mundo exterior. O mecanismo principal para esta extens√£o √© a cria√ß√£o de **Ferramentas (Tools)**.

Uma ferramenta pode ser praticamente qualquer l√≥gica de neg√≥cio encapsulada: uma fun√ß√£o Python para consultar o invent√°rio de produtos num sistema ERP, uma chamada a uma API externa para enviar um email de marketing, ou a execu√ß√£o de um script de an√°lise financeira propriet√°rio. Ao expor esta l√≥gica como uma ferramenta, um agente LangChain pode decidir autonomamente quando e como utiliz√°-la.

O LangChain oferece v√°rios m√©todos para criar ferramentas personalizadas, desde simples decoradores de fun√ß√£o at√© implementa√ß√µes mais complexas. A chave para o sucesso √© fornecer ao LLM uma descri√ß√£o em linguagem natural clara e precisa da ferramenta, incluindo o que ela faz e quais s√£o os seus par√¢metros de entrada. √â essa descri√ß√£o que o LLM utiliza para raciocinar sobre a utilidade da ferramenta no contexto de uma determinada tarefa. Esta capacidade de integrar c√≥digo personalizado transforma o LLM de um mero gerador de texto num verdadeiro orquestrador de processos de neg√≥cio.

---

### **Informa√ß√µes Adicionais do LangChain**

A integra√ß√£o de c√≥digo personalizado constitui apenas o primeiro passo na jornada para a cria√ß√£o de aplica√ß√µes de IA de n√≠vel de produ√ß√£o. A orquestra√ß√£o de agentes, por exemplo, introduz desafios de controlo e fiabilidade que n√£o podem ser adequadamente resolvidos com as sequ√™ncias lineares das Chains tradicionais.

Esta limita√ß√£o exp√µe a necessidade de um paradigma de orquestra√ß√£o mais avan√ßado: o **LangGraph**. Conforme ser√° explorado em detalhe posteriormente, o LangGraph foi projetado especificamente para construir agentes mais robustos e control√°veis, permitindo a cria√ß√£o de fluxos de trabalho com ciclos, ramifica√ß√µes condicionais e a capacidade de auto-corre√ß√£o; capacidades essenciais para sistemas aut√≥nomos complexos.

A transi√ß√£o do modelo de Chains para a arquitetura de grafos do LangGraph √©, portanto, o que distingue a cria√ß√£o de um prot√≥tipo funcional da engenharia de um sistema de IA de real valor comercial. Com a base da integra√ß√£o de ferramentas solidamente estabelecida, o terreno est√° preparado para a explora√ß√£o de arquiteturas avan√ßadas que transformam o potencial da IA em realidade de neg√≥cio.
---

## LangGraph

O **LangGraph** √© uma evolu√ß√£o das ideias do LangChain, mas com foco em **grafos de execu√ß√£o**.  
Isso permite mapear fluxos complexos de decis√£o como se fossem diagramas visuais, trazendo:  

- **Transpar√™ncia**: acompanhamento de cada etapa do racioc√≠nio.  
- **Governan√ßa**: auditoria mais f√°cil em processos cr√≠ticos (como jur√≠dico e sa√∫de).  
- **Flexibilidade**: m√∫ltiplos caminhos de execu√ß√£o em um mesmo sistema.  

**Exemplo:** um sistema de triagem m√©dica que decide se um paciente deve ser atendido por IA, direcionado a um humano ou encaminhado a um especialista.  

Essa abordagem √© indicada para **sistemas cr√≠ticos** que exigem rastreabilidade e controle.  

____ parte Notion

### **A Era das Cadeias Lineares**

No contexto do LangChain, um DAG representa um fluxo de trabalho onde os dados se movem em uma √∫nica dire√ß√£o, de um passo para o pr√≥ximo, sem a possibilidade de retornar a um estado anterior. Pense em uma linha de montagem: cada esta√ß√£o realiza uma tarefa espec√≠fica e passa o produto para a pr√≥xima, mas o produto nunca volta para uma esta√ß√£o anterior. Esse modelo √© extraordinariamente eficaz para tarefas sequenciais e previs√≠veis. Um exemplo cl√°ssico √© um pipeline de Gera√ß√£o Aumentada por Recupera√ß√£o (RAG - *Retrieval-Augmented Generation*):

1. **Entrada do Usu√°rio:** Recebe uma pergunta.
2. **Recupera√ß√£o:** Busca documentos relevantes em uma base de dados vetorial.
3. **Aumento:** Adiciona o contexto recuperado √† pergunta original.
4. **Gera√ß√£o:** Envia o prompt aumentado para um LLM para gerar a resposta final.

Este fluxo √© linear, determin√≠stico e perfeitamente modelado por um DAG. Cada passo flui para o seguinte, e o processo termina com a resposta. Para uma vasta gama de aplica√ß√µes, desde chatbots de perguntas e respostas at√© sumarizadores de documentos, essa abordagem √© suficiente e robusta.

---

### **A Barreira da Aciclicidade**

Contudo, √† medida que a ambi√ß√£o por tr√°s das aplica√ß√µes de IA cresceu, as limita√ß√µes do paradigma DAG tornaram-se cada vez mais evidentes, especialmente no desenvolvimento de agentes aut√¥nomos. Agentes verdadeiramente inteligentes n√£o operam em linhas retas; eles deliberam, corrigem seus pr√≥prios erros e adaptam suas estrat√©gias com base em novas informa√ß√µes. A natureza estritamente unidirecional dos DAGs imp√µe barreiras fundamentais a esse tipo de comportamento din√¢mico.

- **Incapacidade de Itera√ß√£o e Auto-corre√ß√£o:** A principal limita√ß√£o √© a aus√™ncia de ciclos. Um agente aut√¥nomo frequentemente precisa executar um loop de "pensamento". Por exemplo, ao tentar responder a uma pergunta complexa, um agente pode usar uma ferramenta de busca, analisar os resultados e concluir que a informa√ß√£o √© insuficiente. Sua pr√≥xima a√ß√£o l√≥gica seria refinar a consulta de busca e tentar novamente. Em um DAG, esse retorno ao passo de "busca" √© imposs√≠vel por defini√ß√£o. O fluxo s√≥ pode seguir em frente, impedindo o agente de iterar em dire√ß√£o a uma solu√ß√£o melhor.
- **Dificuldade em Implementar L√≥gica Condicional Complexa:** Embora os DAGs possam suportar ramifica√ß√µes (um passo pode levar a diferentes caminhos), gerenciar uma l√≥gica condicional sofisticada torna-se complicado. Imagine um agente que, ap√≥s executar uma ferramenta, precisa decidir entre tr√™s ou quatro a√ß√µes poss√≠veis, incluindo a repeti√ß√£o da mesma ferramenta com par√¢metros diferentes ou a transi√ß√£o para uma ferramenta completamente nova. Modelar essa l√≥gica complexa, onde os caminhos podem precisar convergir ou retornar a um ponto anterior, √© antinatural e convoluto dentro das restri√ß√µes de um grafo ac√≠clico.
- **Interven√ß√£o Humana como um "Hack":** A integra√ß√£o de supervis√£o humana (Human-in-the-Loop - HITL) em um DAG muitas vezes se assemelha a uma solu√ß√£o improvisada. Inserir um ponto de verifica√ß√£o para valida√ß√£o humana que pode, potencialmente, reenviar o fluxo para um est√°gio anterior, quebra a pureza do modelo DAG e requer implementa√ß√µes personalizadas complexas. N√£o √© uma capacidade nativa, mas sim um "hack" adicionado ao sistema.

---

### **A Mudan√ßa de Paradigma de "Fluxo de Trabalho" para "Modelo de Estado"**

A constata√ß√£o de que os DAGs eram insuficientes para a pr√≥xima gera√ß√£o de agentes de IA levou a uma reavalia√ß√£o fundamental da pr√≥pria natureza da orquestra√ß√£o. A limita√ß√£o n√£o era apenas a aus√™ncia de ciclos, mas a falta de um conceito central e persistente de "estado" que evolui ao longo desses ciclos. Um DAG √©, em ess√™ncia, um pipeline de transforma√ß√£o de dados, an√°logo a um processo de ETL (*Extract, Transform, Load*). Os dados entram, s√£o processados em etapas e saem.

LangGraph surge como a resposta a essa limita√ß√£o, mas n√£o √© meramente um "LangChain com loops". Ele representa uma mudan√ßa filos√≥fica profunda. A principal abstra√ß√£o introduzida pelo LangGraph √© o StatefulGraph, ou Grafo de Estado. Essa mudan√ßa de arquitetura reflete uma transi√ß√£o na forma como concebemos a orquestra√ß√£o de LLMs: passamos de v√™-la como um *processo de ETL de dados* para v√™-la como a *simula√ß√£o de um agente cognitivo com mem√≥ria e capacidade de racioc√≠nio*.

Neste novo paradigma:

- O **Estado** √© a mem√≥ria de trabalho do agente. √â um objeto central que cont√©m todas as informa√ß√µes relevantes sobre a tarefa em andamento: a pergunta original, os resultados de ferramentas, as tentativas anteriores, as mensagens trocadas, etc.
- Os **N√≥s** do grafo s√£o as a√ß√µes ou opera√ß√µes que o agente pode realizar (chamar um LLM, usar uma ferramenta, agregar dados).
- Os **Ciclos** e as **Arestas Condicionais** representam o processo de "pensamento" do agente, permitindo-lhe avaliar o estado atual e decidir qual a√ß√£o tomar em seguida.

Portanto, LangGraph n√£o deve ser visto como uma simples atualiza√ß√£o incremental do LangChain. Ele √© um framework projetado para um paradigma de programa√ß√£o de IA inteiramente novo, focado na cria√ß√£o de sistemas din√¢micos, com estado e c√≠clicos, que podem emular processos de delibera√ß√£o e auto-corre√ß√£o, abrindo as portas para a constru√ß√£o de agentes verdadeiramente aut√¥nomos e robustos.

---

## **Se√ß√£o 2: Mergulho Profundo no LangGraph: Arquitetura para Agentes Aut√¥nomos**

Para construir agentes capazes de racioc√≠nio complexo, itera√ß√£o e adapta√ß√£o, √© necess√°ria uma arquitetura que v√° al√©m dos fluxos lineares. LangGraph fornece exatamente isso, introduzindo um modelo computacional baseado em grafos de estado. Esta se√ß√£o descontr√≥i a arquitetura do LangGraph em seus componentes fundamentais, fornecendo um modelo mental claro de seu funcionamento e culminando em um exemplo pr√°tico e comentado.

### **2.1. O Paradigma do Grafo de Estado (StatefulGraph): O Cora√ß√£o do Agente**

No centro do LangGraph est√° a classe StatefulGraph. Diferente dos grafos tradicionais que simplesmente passam a sa√≠da de um n√≥ como entrada para o pr√≥ximo, um StatefulGraph opera sobre um objeto de estado centralizado e persistente. Este objeto de estado, frequentemente definido como uma TypedDict ou um BaseModel Pydantic em Python, serve como a "mem√≥ria de trabalho" ou o "contexto" completo da execu√ß√£o do agente.

Cada n√≥ no grafo recebe o estado atual completo como sua entrada. Ao concluir sua computa√ß√£o, o n√≥ n√£o retorna apenas um resultado isolado, mas sim um objeto que especifica como o estado central deve ser atualizado. O LangGraph ent√£o se encarrega de fundir essa atualiza√ß√£o no estado principal.

A import√¢ncia de um estado centralizado √© multifacetada:

- **Consist√™ncia dos Dados:** Garante que todos os n√≥s operem com a mesma vis√£o do mundo, eliminando a necessidade de passar manualmente dezenas de par√¢metros entre as fun√ß√µes.
- **Depura√ß√£o e Observabilidade:** Em qualquer ponto da execu√ß√£o, √© poss√≠vel inspecionar o objeto de estado para entender exatamente o que o agente "sabe" e "pensa". Isso √© inestim√°vel para depurar fluxos complexos.
- **Persist√™ncia e Retomada:** O estado pode ser facilmente serializado e salvo (um processo conhecido como *checkpointing*). Isso permite que execu√ß√µes muito longas sejam interrompidas e retomadas posteriormente, ou que o hist√≥rico completo de uma intera√ß√£o seja auditado.

Em suma, o StatefulGraph transforma a computa√ß√£o de um simples fluxo de dados para a simula√ß√£o de um processo com mem√≥ria, onde o estado evolui a cada passo, refletindo o progresso do agente em dire√ß√£o ao seu objetivo.

### **2.2. Anatomia de um Grafo em LangGraph: N√≥s e Arestas**

Um grafo em LangGraph √© composto por dois elementos prim√°rios: n√≥s (*nodes*), que representam as unidades de computa√ß√£o, e arestas (*edges*), que definem o fluxo de controle entre esses n√≥s.

### **N√≥s (Nodes): As Unidades de Computa√ß√£o**

Um n√≥ em LangGraph √© definido de forma extremamente flex√≠vel: pode ser qualquer fun√ß√£o ou objeto "cham√°vel" (*callable*) em Python. Essa flexibilidade permite que um n√≥ encapsule uma variedade de opera√ß√µes, desde as mais simples √†s mais complexas:

- Uma chamada a um LLM para gerar texto ou tomar uma decis√£o.
- A execu√ß√£o de uma ferramenta (ex: uma busca na web, uma consulta a um banco de dados, a execu√ß√£o de um c√≥digo).
- Uma fun√ß√£o de agrega√ß√£o que processa os resultados de m√∫ltiplos n√≥s anteriores.
- Uma chamada para a interface do usu√°rio para solicitar feedback.
- At√© mesmo a invoca√ß√£o de outro grafo LangGraph, permitindo a cria√ß√£o de sistemas hier√°rquicos.

A √∫nica restri√ß√£o √© que a fun√ß√£o do n√≥ deve aceitar o objeto de estado como seu √∫nico argumento e retornar um dicion√°rio (ou um objeto similar) contendo as atualiza√ß√µes a serem aplicadas ao estado.

### **Arestas (Edges): As Vias de L√≥gica e Controle**

As arestas conectam os n√≥s e ditam a ordem de execu√ß√£o. LangGraph suporta dois tipos principais de arestas, e √© na combina√ß√£o delas que reside o poder do framework.

- **Arestas Padr√£o:** Uma aresta padr√£o define uma transi√ß√£o incondicional. A instru√ß√£o graph.add_edge("A", "B") significa que, sempre que o n√≥ "A" terminar sua execu√ß√£o, o fluxo de controle passar√° imediatamente para o n√≥ "B". Isso √© usado para sequ√™ncias l√≥gicas fixas dentro do comportamento do agente.
- **Arestas Condicionais (Conditional Edges):** Este √© o mecanismo que habilita a verdadeira intelig√™ncia e autonomia. Uma aresta condicional permite que o fluxo de controle seja roteado para diferentes n√≥s com base no conte√∫do atual do objeto de estado. A implementa√ß√£o funciona da seguinte maneira:
1. Um n√≥ de origem (ex: "analisar_resultados") √© conectado a um n√≥ especial de roteamento.
2. Este n√≥ de roteamento √© uma fun√ß√£o que inspeciona o estado (ex: verifica se uma ferramenta foi chamada, se a resposta foi encontrada, etc.).
3. Com base nessa inspe√ß√£o, a fun√ß√£o de roteamento retorna o nome do pr√≥ximo n√≥ a ser executado.
4. O grafo √© configurado com um mapeamento que conecta os poss√≠veis retornos da fun√ß√£o de roteamento aos n√≥s de destino correspondentes.

√â atrav√©s das arestas condicionais que um agente pode decidir se deve chamar outra ferramenta, refinar sua abordagem, pedir ajuda a um humano ou finalizar o trabalho por ter alcan√ßado uma solu√ß√£o satisfat√≥ria. Isso permite a implementa√ß√£o de ciclos, l√≥gica de ramifica√ß√£o complexa e comportamento verdadeiramente din√¢mico.

### **2.3. Construindo seu Primeiro Agente C√≠clico (Tutorial com C√≥digo)**

Para solidificar esses conceitos, vamos construir um agente de pesquisa simples, mas poderoso. O objetivo do agente √© receber uma pergunta, usar uma ferramenta de busca para encontrar informa√ß√µes e, crucialmente, decidir se a informa√ß√£o encontrada √© suficiente para responder ou se precisa refinar a busca e tentar novamente. Este comportamento c√≠clico √© o diferencial do LangGraph.

**Cen√°rio:** Um agente que responde a perguntas usando uma busca na web simulada.

**Passo 1: Defini√ß√£o do Estado**

Primeiro, definimos a estrutura da "mem√≥ria" do nosso agente usando TypedDict. O estado ir√° rastrear a pergunta, as mensagens trocadas (para manter o hist√≥rico), e o n√∫mero de itera√ß√µes.

```{code-block} python
from typing import List, TypedDict
from langgraph.graph import StateGraph, END
import operator # Usado para acumular mensagens

# Define a estrutura do estado do nosso grafo.
# Este objeto ser√° passado entre todos os n√≥s.
class AgentState(TypedDict):
    question: str
    messages: Annotated[list, operator.add]
    # O Annotated e o operator.add permitem que a chave 'messages' funcione como um acumulador.
    # Novas mensagens ser√£o adicionadas √† lista existente em vez de substitu√≠-la.
    iterations: int
``

**Passo 2: Defini√ß√£o dos N√≥s**

Agora, criamos as fun√ß√µes Python que servir√£o como os n√≥s do nosso grafo. Cada fun√ß√£o recebe o estado e retorna um dicion√°rio com as atualiza√ß√µes.

```{code-block} python
import random

# N√≥ 1: A ferramenta de busca (simulada)
def search_tool(state: AgentState) -> dict:
    print("---EXECUTANDO FERRAMENTA DE BUSCA---")
    question = state['question']
    iterations = state['iterations']
    
    # Simula uma busca que pode ou n√£o encontrar a resposta na primeira tentativa
    if "LangGraph" in question and iterations == 0:
        search_result = "Informa√ß√£o insuficiente sobre LangGraph. Tente refinar a busca."
    else:
        search_result = "LangGraph √© uma biblioteca para construir agentes de IA com estado e ciclos."
    
    return {"messages": [search_result], "iterations": iterations + 1}

# N√≥ 2: O LLM que analisa os resultados e gera a resposta final
def generate_answer(state: AgentState) -> dict:
    print("---GERANDO RESPOSTA FINAL---")
    last_message = state['messages'][-1]
    if "insuficiente" in last_message:
        # Se a busca falhou, o agente decide refinar a pergunta
        print(">> Decis√£o: Refinar a busca.")
        refined_question = state['question'] + " (detalhado)"
        action_message = "Refinando a busca para obter mais detalhes."
        return {"question": refined_question, "messages": [action_message]}
    else:
        # Se a busca foi bem-sucedida, gera a resposta final
        print(">> Decis√£o: Gerar resposta final.")
        final_answer = f"Resposta final encontrada: {last_message}"
        return {"messages": [final_answer]}
```

**Passo 3: Defini√ß√£o da L√≥gica C√≠clica (N√≥ de Roteamento)**

Este √© o c√©rebro do nosso agente. A fun√ß√£o `should_continue` inspeciona o estado e decide para onde o fluxo deve ir em seguida: de volta para a busca ou para o final.

```python
def should_continue(state: AgentState) -> str:
    print("---VERIFICANDO CONDI√á√ÉO DE CONTINUA√á√ÉO---")
    last_message = state['messages'][-1]
    # Se a √∫ltima mensagem indica que a busca precisa ser refinada, continuamos o ciclo
    if "Refinando a busca" in last_message:
        return "continue"
    # Se atingimos um limite de itera√ß√µes ou encontramos a resposta, terminamos
    elif state['iterations'] >= 3:
        return "end"
    else:
        return "end"
```

**Passo 4: Constru√ß√£o e Compila√ß√£o do Grafo**

Finalmente, montamos o grafo, adicionando os n√≥s e as arestas (incluindo a aresta condicional).

```python
# Instancia o grafo, associando-o √† nossa defini√ß√£o de estado
workflow = StateGraph(AgentState)

# Adiciona os n√≥s ao grafo
workflow.add_node("search", search_tool)
workflow.add_node("analyze", generate_and_analyze)

# Define o ponto de entrada do grafo
workflow.set_entry_point("search")

# Adiciona as arestas
# Ap√≥s a busca, sempre vamos para a gera√ß√£o/an√°lise
workflow.add_edge("search", "analyze")

# Adiciona a aresta condicional: o "c√©rebro" do agente
workflow.add_conditional_edges(
    "analyze",  # N√≥ de origem
    should_continue,  # Fun√ß√£o de roteamento
    {
        "continue": "search",  # Se a fun√ß√£o retornar "continue", volta para a busca (CICLO)
        "end": END  # Se a fun√ß√£o retornar "end", termina a execu√ß√£o
    }
)

# Compila o grafo em um objeto execut√°vel
app = workflow.compile()
```

**Passo 5: Execu√ß√£o do Grafo**

Agora podemos executar nosso agente. Observe como ele executa o ciclo uma vez antes de encontrar a resposta.

```python
# Executa o grafo com uma entrada inicial
initial_input = {"question": "O que √© LangGraph?", "messages": [], "iterations": 0}
for event in app.stream(initial_input, {"recursion_limit": 5}):
    for key, value in event.items():
        print(f"\nN√≥: {key}")
        print(f"Estado atualizado: {value}")

# Sa√≠da Esperada:
#N√≥: search
#Estado atualizado: {'messages': ['Informa√ß√£o insuficiente sobre LangGraph. Tente refinar a busca.'], 'iterations': 1}
#---ANALISANDO RESULTADO DA BUSCA---
#>> Decis√£o: Refinar a busca.
#N√≥: analyze
#Estado atualizado: {'question': 'O que √© LangGraph? (detalhado)', 'messages': ['Informa√ß√£o insuficiente sobre LangGraph. Tente refinar a busca.', 'Refinando a busca para obter mais detalhes.']}
#---VERIFICANDO CONDI√á√ÉO DE CONTINUA√á√ÉO---
#---EXECUTANDO FERRAMENTA DE BUSCA---
#N√≥: search
#Estado atualizado: {'messages': ['Informa√ß√£o insuficiente sobre LangGraph. Tente refinar a busca.', 'Refinando a busca para obter mais detalhes.', 'LangGraph √© uma biblioteca para construir agentes de IA com estado e ciclos, permitindo a cria√ß√£o de aplica√ß√µes LLM confi√°veis e robustas.'], 'iterations': 2}
#---ANALISANDO RESULTADO DA BUSCA---
#>> Decis√£o: Gerar resposta final.
#N√≥: analyze
#Estado atualizado: {'messages': ['Informa√ß√£o insuficiente sobre LangGraph. Tente refinar a busca.', 'Refinando a busca para obter mais detalhes.', 'LangGraph √© uma biblioteca para construir agentes de IA com estado e ciclos, permitindo a cria√ß√£o de aplica√ß√µes LLM confi√°veis e robustas.', 'Resposta final encontrada: LangGraph √© uma biblioteca para construir agentes de IA com estado e ciclos, permitindo a cria√ß√£o de aplica√ß√µes LLM confi√°veis e robustas.']}
#---VERIFICANDO CONDI√á√ÉO DE CONTINUA√á√ÉO---
#N√≥: __end__
#Estado atualizado: {'question': 'O que √© LangGraph? (detalhado)', 'messages': ['Informa√ß√£o insuficiente sobre LangGraph. Tente refinar a busca.', 'Refinando a busca para obter mais detalhes.', 'LangGraph √© uma biblioteca para construir agentes de IA com estado e ciclos, permitindo a cria√ß√£o de aplica√ß√µes LLM confi√°veis e robustas.', 'Resposta final encontrada: LangGraph √© uma biblioteca para construir agentes de IA com estado e ciclos, permitindo a cria√ß√£o de aplica√ß√µes LLM confi√°veis e robustas.'], 'iterations': 2}
```

Este exemplo simples demonstra o poder do paradigma do LangGraph. A capacidade de criar ciclos controlados por l√≥gica condicional √© o que permite a constru√ß√£o de agentes que podem raciocinar, planejar e se auto-corrigir.

### 2.4. Padr√µes Avan√ßados: Multi-Agentes e Interven√ß√£o Humana

A arquitetura do LangGraph se estende elegantemente a padr√µes muito mais sofisticados, essenciais para aplica√ß√µes do mundo real.

### Colabora√ß√£o Multi-Agente

Sistemas complexos raramente s√£o resolvidos por um √∫nico agente monol√≠tico. Uma abordagem mais robusta √© criar um sistema de m√∫ltiplos agentes, cada um com sua especialidade. LangGraph √© ideal para orquestrar essa colabora√ß√£o. Uma arquitetura comum √© a do "supervisor-trabalhador":

- Um **Grafo Supervisor** atua como o orquestrador principal. Seu estado rastreia a tarefa geral e delega subtarefas.
- Cada **Agente Trabalhador** √©, ele pr√≥prio, um grafo LangGraph compilado, especializado em uma fun√ß√£o (ex: um "Pesquisador", um "Analista de Dados", um "Escritor").
- O supervisor, atrav√©s de suas arestas condicionais, invoca o grafo trabalhador apropriado para cada subtarefa, aguarda o resultado, atualiza seu estado global e decide o pr√≥ximo passo.

Essa abordagem modular torna o sistema mais f√°cil de desenvolver, testar e manter.

### Interven√ß√£o Humana no Loop (HITL)

Para aplica√ß√µes de miss√£o cr√≠tica, a autonomia total pode ser um risco. LangGraph fornece um mecanismo nativo e elegante para implementar a Interven√ß√£o Humana no Loop (HITL). Um n√≥ especial pode ser configurado para gerar uma `Interrupt`, pausando a execu√ß√£o do grafo e esperando por uma entrada externa. Uma aresta condicional pode ser usada para direcionar o fluxo para este n√≥ de interrup√ß√£o sempre que o agente encontrar uma situa√ß√£o de baixa confian√ßa, ambiguidade ou antes de executar uma a√ß√£o de alto impacto (ex: enviar um e-mail para um cliente, executar uma transa√ß√£o financeira). Ap√≥s a interven√ß√£o humana, o estado √© atualizado com a orienta√ß√£o fornecida, e a execu√ß√£o do grafo pode ser retomada a partir do ponto em que parou.

Essa capacidade de integrar perfeitamente a supervis√£o humana transforma o LangGraph de uma ferramenta para construir agentes aut√¥nomos em uma plataforma para construir sistemas de IA colaborativos e seguros. Isso nos leva a uma percep√ß√£o mais profunda sobre o papel do LangGraph no ecossistema de IA. Ele n√£o √© apenas uma ferramenta para criar agentes "inteligentes", mas uma ferramenta crucial para construir agentes *audit√°veis, depur√°veis e seguros*. A combina√ß√£o de controle expl√≠cito sobre o fluxo, gest√£o de estado transparente e mecanismos nativos para interrup√ß√£o e continua√ß√£o s√£o os pilares fundamentais dos sistemas de "IA Confi√°vel" (*Trustworthy AI*). A capacidade de inspecionar o estado em cada passo, entender *por que* uma decis√£o foi tomada (atrav√©s da l√≥gica das arestas condicionais) e intervir quando necess√°rio, aborda diretamente o desafio da "caixa-preta" em sistemas de agentes complexos, tornando o LangGraph uma escolha estrat√©gica para aplica√ß√µes de n√≠vel empresarial.

### **Conclus√£o: Da Autonomia √† Confiabilidade em Produ√ß√£o**

A jornada atrav√©s da arquitetura do LangGraph revela uma evolu√ß√£o fundamental na orquestra√ß√£o de LLMs. As limita√ß√µes inerentes aos Grafos Ac√≠clicos Dirigidos (DAGs) para a constru√ß√£o de agentes inteligentes ‚Äî notavelmente a sua incapacidade de iterar e auto-corrigir ‚Äî necessitaram de uma mudan√ßa de paradigma. O LangGraph aborda este desafio ao introduzir o `StatefulGraph`, transformando o modelo de desenvolvimento de um pipeline de dados linear para a simula√ß√£o de um processo cognitivo com mem√≥ria. Atrav√©s da implementa√ß√£o de n√≥s, arestas condicionais e um objeto de estado persistente, torna-se poss√≠vel construir agentes capazes de racioc√≠nio c√≠clico, delibera√ß√£o e adapta√ß√£o din√¢mica.

As implica√ß√µes desta arquitetura estendem-se muito para al√©m da mera capacidade funcional. A capacidade de orquestrar sistemas multi-agente, onde agentes especializados colaboram sob a dire√ß√£o de um supervisor, permite a decomposi√ß√£o modular de problemas complexos.

No entanto, a integra√ß√£o nativa de padr√µes de Interven√ß√£o Humana no Loop (HITL) √© talvez a caracter√≠stica mais cr√≠tica para a ado√ß√£o empresarial. Ela fornece um mecanismo crucial para o controlo e a seguran√ßa, permitindo a supervis√£o humana antes da execu√ß√£o de a√ß√µes de alto impacto. Isto transforma o LangGraph de um framework para construir agentes aut√≥nomos numa plataforma para a engenharia de sistemas de intelig√™ncia **confi√°veis, audit√°veis e seguros**.

Com o n√∫cleo l√≥gico do agente agora definido, o foco deve deslocar-se da orquestra√ß√£o para a implementa√ß√£o e implementa√ß√£o. Como √© que um agente com estado e potencialmente de longa dura√ß√£o √© alojado? Que padr√µes arquitet√≥nicos ‚Äî Monol√≠tico, Microsservi√ßos, Serverless ‚Äî s√£o mais adequados para gerir estas novas cargas de trabalho? Como √© que estes sistemas s√£o monitorizados, escalados e mantidos num ambiente de produ√ß√£o? Estas quest√µes de arquitetura de sistemas e MLOps representam a pr√≥xima fronteira na transforma√ß√£o de um agente poderoso num servi√ßo robusto de n√≠vel empresarial.

---

## Streamlit

O **Streamlit** √© um framework em Python que permite criar **aplica√ß√µes interativas de dados e IA** com poucas linhas de c√≥digo.  

**Aplica√ß√µes t√≠picas:**  
- Dashboards din√¢micos para visualiza√ß√£o de m√©tricas.  
- Prot√≥tipos de interfaces para modelos de Machine Learning.  
- Ferramentas internas para an√°lise explorat√≥ria de dados.  

**Exemplo pr√°tico:** um analista de dados pode compartilhar em minutos um app que mostra previs√µes de vendas com base em modelos de regress√£o.  

Sua simplicidade o torna muito popular em equipes de **Data Science** {cite}`streamlit2021`.  

---

## Gradio

O **Gradio** simplifica a cria√ß√£o de **interfaces web acess√≠veis** para modelos de IA.  
Com ele, √© poss√≠vel transformar um modelo em uma aplica√ß√£o interativa em poucos minutos, sem precisar escrever HTML, CSS ou JavaScript.  

**Exemplos de uso:**  
- Uma p√°gina onde usu√°rios fazem upload de imagens para classifica√ß√£o autom√°tica.  
- Um demo p√∫blico de gera√ß√£o de voz a partir de texto.  

√â bastante utilizado para **demonstra√ß√µes p√∫blicas e testes de usabilidade**, al√©m de ser integrado ao ecossistema **Hugging Face** {cite}`gradio2021`.  
________________

O **Gradio** √© uma biblioteca de c√≥digo aberto em Python que simplifica a cria√ß√£o de interfaces de usu√°rio (UI) para modelos de machine learning, APIs e fun√ß√µes Python arbitr√°rias. Sua principal vantagem √© a velocidade e a facilidade com que se pode construir uma demonstra√ß√£o interativa e compartilh√°vel, permitindo que qualquer pessoa, mesmo sem conhecimento t√©cnico, possa testar um modelo diretamente do navegador.

Diferente de frameworks mais gen√©ricos, o Gradio foi projetado com o fluxo de trabalho de IA em mente: mapear fun√ß√µes de entrada (input) e sa√≠da (output) para componentes interativos.

---

### **Parte 1: Primeiros Passos**

Nesta se√ß√£o, vamos configurar o ambiente e criar nossa primeira interface com Gradio.

### **1. Configura√ß√£o do Ambiente**

Assim como em outros projetos Python, √© essencial ter o Python instalado. O uso de um editor de c√≥digo como o Visual Studio Code (VS Code) √© altamente recomendado.

**Boas Pr√°ticas: Ambiente Virtual**
Para manter as depend√™ncias do projeto organizadas e evitar conflitos, o uso de um ambiente virtual √© fundamental.

1. **Crie uma pasta** para o seu projeto e, dentro dela, abra o terminal.
2. **Crie o ambiente virtual**:

`python -m venv venv`

4. Ative o ambiente virtual:

- No Windows: `venv\Scripts\activate`
- No macOS/Linux: `source venv/bin/activate`

### **2. Instala√ß√£o do Gradio**

Com o ambiente virtual ativado, instale o Gradio usando o `pip`:

`pip install gradio`

A instala√ß√£o inclui todas as depend√™ncias necess√°rias para come√ßar a criar suas interfaces.

### **3. Primeira Aplica√ß√£o: Uma Fun√ß√£o Simples**

1. Crie um arquivo Python, por exemplo, `app_gradio.py`.
2. Defina uma fun√ß√£o Python e use o Gradio para criar uma interface para ela.

**Exemplo de C√≥digo:** `app_gradio.py`

```{code-block} python
import gradio as gr

# 1. Defina a fun√ß√£o que seu app ir√° executar
def saudar(nome):
    return f"Ol√°, {nome}! Bem-vindo ao Gradio."

# 2. Crie a interface Gradio
#    - fn: a fun√ß√£o a ser chamada
#    - inputs: o tipo de componente para a entrada (texto, imagem, etc.)
#    - outputs: o tipo de componente para a sa√≠da
iface = gr.Interface(fn=saudar, inputs="text", outputs="text")

# 3. Inicie a aplica√ß√£o
iface.launch()
```

### **4. Executando a Aplica√ß√£o**

No terminal, com o ambiente virtual ativado, execute o comando:

`python app_gradio.py`

O Gradio iniciar√° um servidor local e imprimir√° um endere√ßo no console (geralmente `http://127.0.0.1:7860`). Abra este link no seu navegador para ver e interagir com sua aplica√ß√£o. Uma das funcionalidades mais poderosas √© que, ao usar `iface.launch(share=True)`, o Gradio gera um link p√∫blico tempor√°rio, permitindo que voc√™ compartilhe sua demo com qualquer pessoa no mundo por 72 horas.

### **Parte 2: Adicionando Interatividade com Componentes**

O Gradio brilha na variedade de componentes de entrada e sa√≠da que oferece, prontos para uso em tarefas de IA.

### **1. Componentes de Entrada (Inputs)**

Os inputs definem como o usu√°rio fornecer√° dados para a sua fun√ß√£o.

- `gr.Textbox()`: Campo de texto, com op√ß√µes para n√∫mero de linhas e placeholders.
- `gr.Slider()`: Controle deslizante para selecionar n√∫meros.
- `gr.Dropdown()`: Menu suspenso com op√ß√µes pr√©-definidas.
- `gr.Image()`: Para upload de imagens, com op√ß√µes para definir a fonte (upload, webcam, etc.).
- `gr.Audio()`: Para upload ou grava√ß√£o de √°udio.

**Exemplo de C√≥digo com M√∫ltiplos Inputs:**

```{code-block} python
import gradio as gr

def gerar_historia(personagem, lugar, idade):
    return f"Era uma vez, em {lugar}, vivia um(a) {personagem} de {idade} anos. A aventura estava prestes a come√ßar..."

iface = gr.Interface(
    fn=gerar_historia,
    inputs=[
        gr.Textbox(label="Nome do Personagem"),
        gr.Dropdown(["uma floresta m√°gica", "uma cidade futurista", "um castelo antigo"], label="Onde a hist√≥ria se passa?"),
        gr.Slider(minimum=10, maximum=100, step=1, label="Idade do Personagem")
    ],
    outputs="text",
    title="Gerador de Hist√≥rias com IA"
)

iface.launch()
```

### **2. Componentes de Sa√≠da (Outputs)**

Os outputs definem como o resultado da sua fun√ß√£o ser√° exibido.

- `gr.Textbox()`: Exibe texto simples ou formatado.
- `gr.Image()`: Exibe uma imagem (retornada como um array NumPy ou caminho do arquivo).
- `gr.Label()`: Ideal para tarefas de classifica√ß√£o, mostrando as classes e suas probabilidades.
- `gr.Dataframe()`: Exibe um DataFrame do Pandas.
- `gr.Plot()`: Exibe gr√°ficos de bibliotecas como Matplotlib ou Plotly.

**Exemplo de C√≥digo com Output de Imagem (Conceitual):**

```{code-block} python
import gradio as gr
import numpy as np

# Fun√ß√£o fict√≠cia que gera uma imagem (um gradiente)
def gerar_imagem_gradiente(cor1, cor2):
    # L√≥gica para criar uma imagem (array NumPy)
    # Neste exemplo, criamos uma imagem preta simples
    imagem_array = np.zeros((100, 200, 3), dtype=np.uint8) 
    # O coment√°rio abaixo deixa claro que a l√≥gica de gera√ß√£o da imagem foi omitida
    # ... aqui iria o c√≥digo para gerar o gradiente real ...
    print("Gerando imagem conceitual...") # Opcional: um print no console √© √∫til para debug
    return imagem_array

iface = gr.Interface(
    fn=gerar_imagem_gradiente,
    inputs=["text", "text"],
    outputs=gr.Image(label="Resultado do Gradiente"),
    title="Gerador de Imagens"
)

iface.launch()
```

### **Parte 3: Aplica√ß√µes Robustas**

Para criar demos mais complexas e organizadas, voc√™ pode usar blocos e gerenciar o estado.

### **1. Organizando o Layout com Blocos (`gr.Blocks`)**

Para ter controle total sobre onde os componentes aparecem, use `gr.Blocks`. Isso permite criar layouts com linhas, colunas e abas, oferecendo muito mais flexibilidade do que `gr.Interface`.

**Exemplo de C√≥digo:**

```{code-block} python
import gradio as gr

def saudacao_completa(nome, saudacao):
    return f"{saudacao}, {nome}!"

with gr.Blocks() as demo:
    gr.Markdown("# App de Sauda√ß√µes Personalizadas")
    
    with gr.Row():
        # Coluna 1: Entradas
        with gr.Column(scale=1):
            input_nome = gr.Textbox(label="Seu Nome")
            input_saudacao = gr.Dropdown(["Ol√°", "Bom dia", "Boa noite"], label="Escolha a Sauda√ß√£o")
            btn = gr.Button("Gerar Sauda√ß√£o")
    
        # Coluna 2: Sa√≠da
        with gr.Column(scale=2):
            output_texto = gr.Textbox(label="Resultado")

    # Define a interatividade: quando o bot√£o for clicado, chame a fun√ß√£o
    btn.click(fn=saudacao_completa, inputs=[input_nome, input_saudacao], outputs=output_texto)

demo.launch()
```

### **2. Gerenciando o Estado (`gr.State`)**

Em aplica√ß√µes interativas, como um chatbot, voc√™ precisa manter o hist√≥rico da conversa. O Gradio usa o componente `gr.State` para passar dados entre as execu√ß√µes de uma fun√ß√£o sem exibi-los na UI.

**Exemplo de C√≥digo: Chatbot Simples**

```{code-block} python
import gradio as gr
import random

def chatbot_resposta(mensagem, historico):
    # Adiciona a mensagem do usu√°rio ao hist√≥rico
    historico.append((mensagem, ""))
    
    # Simula uma resposta do bot
    respostas_bot = ["Que interessante!", "Conte-me mais.", "Entendo."]
    resposta_bot = random.choice(respostas_bot)
    
    # Adiciona a resposta do bot ao hist√≥rico
    historico[-1] = (mensagem, resposta_bot)
    
    return historico, "" # Retorna o hist√≥rico atualizado e limpa a caixa de texto

with gr.Blocks() as demo:
    gr.Markdown("## Chatbot Simples")
    
    # Componente de estado para armazenar o hist√≥rico (invis√≠vel na UI)
    historico_estado = gr.State([])
    
    chatbot = gr.Chatbot()
    caixa_texto = gr.Textbox(placeholder="Digite sua mensagem aqui...")
    
    # A fun√ß√£o `chatbot_resposta` recebe a mensagem e o estado do hist√≥rico
    caixa_texto.submit(
        fn=chatbot_resposta,
        inputs=[caixa_texto, historico_estado],
        outputs=[chatbot, caixa_texto] # Atualiza o chatbot e limpa a caixa de texto
    )

demo.launch()
```

### **Parte 4: Compartilhando sua Aplica√ß√£o (Deploy)**

A beleza do Gradio est√° na facilidade de compartilhamento.

1. **Compartilhamento R√°pido (`share=True`)**:
Como mencionado, a forma mais simples de compartilhar √© adicionando o par√¢metro `share=True` ao m√©todo `launch()`:Python

`iface.launch(share=True)`

1. Isso gera um link p√∫blico e seguro (com t√∫nel da Cloudflare) que funciona por 72 horas. Ideal para demos r√°pidas, testes com clientes ou colabora√ß√£o em equipe.
2. **Hospedagem Permanente com Hugging Face Spaces**:
Para uma solu√ß√£o gratuita e permanente, a plataforma Hugging Face Spaces √© a melhor op√ß√£o. Ela √© totalmente integrada ao Gradio.
    - **Crie um Space**: No site da Hugging Face, crie um novo "Space" e escolha o SDK do Gradio.
    - **Adicione seus arquivos**: Envie seu arquivo Python (`app.py`) e um arquivo `requirements.txt` listando as bibliotecas (`gradio`, `pandas`, `transformers`, etc.).
    - **Pronto**: O Hugging Face Spaces automaticamente instala as depend√™ncias e executa sua aplica√ß√£o, fornecendo um link permanente para sua demo.
  
### **Informa√ß√µes Adicionais e Boas Pr√°ticas**

- **Foco na Fun√ß√£o**: O Gradio √© constru√≠do em torno de uma fun√ß√£o Python. Projete sua l√≥gica principal nessa fun√ß√£o e depois construa a UI ao redor dela.
- **Explore a Documenta√ß√£o**: A documenta√ß√£o oficial do Gradio √© rica em exemplos para todos os tipos de componentes e casos de uso.
- **Use Exemplos (`examples`)**: O `gr.Interface` possui um par√¢metro `examples` que permite adicionar exemplos clic√°veis √† sua UI, facilitando o teste para os usu√°rios.
- **Integra√ß√£o com Modelos de IA**: Gradio integra-se perfeitamente com bibliotecas como `transformers`, `PyTorch` e `TensorFlow`, tornando trivial a cria√ß√£o de interfaces para modelos pr√©-treinados.

## WhatsApp API

A integra√ß√£o com o **WhatsApp API** permite conectar chatbots de IA diretamente ao aplicativo de mensagens mais usado no Brasil e em v√°rios pa√≠ses.  

**Casos comuns de uso:**  
- Atendimento automatizado com personaliza√ß√£o de contexto.  
- Suporte ao cliente em escala, sem perder o tom humano.  
- Campanhas de engajamento interativas, segmentadas por perfil.  

Combinada a LLMs e frameworks de orquestra√ß√£o, transforma o WhatsApp em um **canal estrat√©gico de relacionamento** {cite}`meta2022`.  

---

:::{tip}
O ecossistema de ferramentas de IA est√° em constante expans√£o.  
Mais importante do que conhecer todas as op√ß√µes √© saber **qual ferramenta se alinha melhor ao objetivo do projeto, √† maturidade da equipe e ao or√ßamento dispon√≠vel**.  
A escolha certa pode acelerar resultados; a errada pode gerar custos e complexidade desnecess√°rios.
:::

## Canva

O **Canva** √© uma plataforma de design que incorporou recursos de **IA generativa**, como:  
- Cria√ß√£o autom√°tica de imagens.  
- Sugest√£o de layouts e textos.  
- Gera√ß√£o de apresenta√ß√µes com base em descri√ß√µes simples.  

Embora n√£o seja uma ferramenta t√©cnica de desenvolvimento, **democratiza a IA** para profissionais de comunica√ß√£o, marketing e design, ampliando a ado√ß√£o em escala {cite}`canva2023`.  
